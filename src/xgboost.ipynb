{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = pd.read_csv('../data/preprocessed_train.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed_test.csv')\n",
    "\n",
    "# train_data = pd.read_csv('../data/preprocessed_train_CorrDrop.csv')\n",
    "# test_data = pd.read_csv('../data/preprocessed_test_CorrDrop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'UID' column as the index\n",
    "train_data.set_index('UID', inplace=True)\n",
    "\n",
    "# Set the 'UID' column as the index\n",
    "test_data.set_index('UID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for 'Target' column\n",
    "target_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "# Apply the mapping to the 'Target' column\n",
    "train_labels = train_data['Target'].map(target_mapping)\n",
    "\n",
    "# Drop the 'Target' column from the training data\n",
    "train_data = train_data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train data with 22514 data of each class\n",
    "\n",
    "# Separate the data based on the target classes\n",
    "# low_class = train_data[train_labels == 0]\n",
    "# medium_class = train_data[train_labels == 1]\n",
    "# high_class = train_data[train_labels == 2]\n",
    "\n",
    "# # Get the number of samples in each class\n",
    "# low_class_count = len(low_class)\n",
    "# medium_class_count = len(medium_class)\n",
    "# high_class_count = len(high_class)\n",
    "\n",
    "# # Set the number of samples to be selected from each class\n",
    "# num_samples = min(low_class_count, medium_class_count, high_class_count)\n",
    "# num_samples_m = int(num_samples * 1.0)\n",
    "\n",
    "# # Randomly sample data from each class\n",
    "# low_class_sample = low_class.sample(n=num_samples, random_state=seed)\n",
    "# medium_class_sample = medium_class.sample(n=num_samples_m, random_state=seed)\n",
    "# high_class_sample = high_class.sample(n=num_samples, random_state=seed)\n",
    "\n",
    "# # Concatenate the sampled data\n",
    "# train_data_sampled = pd.concat([low_class_sample, medium_class_sample, high_class_sample])\n",
    "\n",
    "# # Separate the features and target variable\n",
    "# X_sampled = train_data_sampled\n",
    "# y_sampled = train_labels.loc[train_data_sampled.index]\n",
    "\n",
    "# # Display the count of unique values in the target variable\n",
    "# print(y_sampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112569, 20)\n",
      "X_valid shape: (112569, 20)\n",
      "y_train shape: (112569,)\n",
      "y_valid shape: (112569,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_labels, test_size=0.1, random_state=seed)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_sampled, y_sampled, test_size=0.1, random_state=seed)\n",
    "# X_train, y_train = X_sampled, y_sampled\n",
    "# X_valid, y_valid = X_sampled, y_sampled\n",
    "X_train, y_train = train_data, train_labels\n",
    "X_valid, y_valid = train_data, train_labels\n",
    "\n",
    "# Display the shapes of the training and validation sets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: 0.5258120047187965\n",
      "Validation F1 Score: 0.5258120047187965\n",
      "Train Accuracy: 0.6916113672503087\n",
      "Validation Accuracy: 0.6916113672503087\n"
     ]
    }
   ],
   "source": [
    "# initialize the models\n",
    "# params = {\n",
    "#     'n_estimators': 200,\n",
    "#     'learning_rate': 0.2,\n",
    "#     'max_depth': 10,\n",
    "#     'min_child_weight': 3,\n",
    "#     'subsample': 0.6,\n",
    "#     'random_state': seed\n",
    "# }\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=seed,\n",
    "    class_weights=[3, 1, 3]\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "train_preds = xgb.predict(X_train)\n",
    "valid_preds = xgb.predict(X_valid)\n",
    "\n",
    "# calculate the f1 score\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# calculate the accuracy\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# display the f1 score and accuracy\n",
    "print(f\"Train F1 Score: {train_f1}\")\n",
    "print(f\"Validation F1 Score: {valid_f1}\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = xgb.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('../data/output/xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   7.9s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   7.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   7.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   7.9s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   8.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   8.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   8.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   8.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   9.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   9.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=  14.4s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=  14.5s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=  14.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=  14.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=  14.6s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=100; total time=   7.1s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=100; total time=   7.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=  17.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=  17.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=  17.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=  17.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=  18.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=  20.9s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=  21.0s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=100; total time=   6.9s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=100; total time=   6.9s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=100; total time=   6.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=  25.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=  25.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=  25.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=  26.3s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=  26.6s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=200; total time=  13.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=  20.8s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=200; total time=  13.8s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=200; total time=  13.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=  21.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=  21.2s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=200; total time=  13.4s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=200; total time=  13.4s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=100; total time=   6.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=100; total time=   6.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=100; total time=   6.5s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=100; total time=   6.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=400; total time=  33.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=400; total time=  33.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=400; total time=  34.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=400; total time=  34.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=400; total time=  34.2s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=400; total time=  26.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=400; total time=  26.3s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=400; total time=  26.5s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=400; total time=  26.7s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=100; total time=   6.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=400; total time=  27.1s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=300; total time=  18.9s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=300; total time=  19.1s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=300; total time=  19.8s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=300; total time=  19.2s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=300; total time=  17.0s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=200; total time=  10.1s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=200; total time=  10.6s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=200; total time=  11.7s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=200; total time=  11.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=200; total time=  11.9s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=400; total time=  20.1s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=400; total time=  20.2s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=400; total time=  21.0s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=300; total time=  12.6s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=400; total time=  21.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=300; total time=  13.2s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=300; total time=  11.5s\n",
      "[CV] END ................learning_rate=0.3, n_estimators=400; total time=  18.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=300; total time=  12.9s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=300; total time=  12.5s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=400; total time=  13.6s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=400; total time=  13.1s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=400; total time=  13.4s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=400; total time=  13.7s\n",
      "[CV] END ................learning_rate=0.5, n_estimators=400; total time=  14.1s\n",
      "{'learning_rate': 0.5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=seed),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ....................max_depth=2, min_child_weight=1; total time=  13.9s\n",
      "[CV] END ....................max_depth=2, min_child_weight=1; total time=  14.0s\n",
      "[CV] END ....................max_depth=2, min_child_weight=2; total time=  14.0s\n",
      "[CV] END ....................max_depth=2, min_child_weight=1; total time=  14.2s\n",
      "[CV] END ....................max_depth=2, min_child_weight=3; total time=  14.0s\n",
      "[CV] END ....................max_depth=2, min_child_weight=3; total time=  14.0s\n",
      "[CV] END ....................max_depth=2, min_child_weight=1; total time=  14.3s\n",
      "[CV] END ....................max_depth=2, min_child_weight=2; total time=  14.1s\n",
      "[CV] END ....................max_depth=2, min_child_weight=4; total time=  14.0s\n",
      "[CV] END ....................max_depth=2, min_child_weight=2; total time=  14.3s\n",
      "[CV] END ....................max_depth=2, min_child_weight=1; total time=  14.4s\n",
      "[CV] END ....................max_depth=2, min_child_weight=2; total time=  14.3s\n",
      "[CV] END ....................max_depth=2, min_child_weight=3; total time=  14.3s\n",
      "[CV] END ....................max_depth=2, min_child_weight=4; total time=  14.1s\n",
      "[CV] END ....................max_depth=2, min_child_weight=2; total time=  14.4s\n",
      "[CV] END ....................max_depth=2, min_child_weight=4; total time=  14.3s\n",
      "[CV] END ....................max_depth=2, min_child_weight=3; total time=  14.6s\n",
      "[CV] END ....................max_depth=2, min_child_weight=3; total time=  14.5s\n",
      "[CV] END ....................max_depth=2, min_child_weight=4; total time=  14.6s\n",
      "[CV] END ....................max_depth=2, min_child_weight=4; total time=  14.7s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=  15.2s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=  15.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=  15.5s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=  15.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=  15.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=3; total time=  15.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=  15.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=  15.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=  16.0s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=  16.0s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=  16.1s\n",
      "[CV] END ....................max_depth=3, min_child_weight=3; total time=  16.0s\n",
      "[CV] END ....................max_depth=3, min_child_weight=3; total time=  16.4s\n",
      "[CV] END ....................max_depth=3, min_child_weight=3; total time=  16.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=4; total time=  16.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=3; total time=  16.9s\n",
      "[CV] END ....................max_depth=3, min_child_weight=4; total time=  16.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=4; total time=  16.6s\n",
      "[CV] END ....................max_depth=3, min_child_weight=4; total time=  16.7s\n",
      "[CV] END ....................max_depth=3, min_child_weight=4; total time=  17.0s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=  21.0s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=  21.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=  21.2s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=  21.1s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=  21.5s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=  21.7s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=  21.7s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=  21.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=3; total time=  21.2s\n",
      "[CV] END ....................max_depth=5, min_child_weight=3; total time=  21.5s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=  21.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=  22.0s\n",
      "[CV] END ....................max_depth=5, min_child_weight=3; total time=  20.9s\n",
      "[CV] END ....................max_depth=5, min_child_weight=3; total time=  20.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=4; total time=  20.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=4; total time=  20.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=4; total time=  20.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=4; total time=  21.2s\n",
      "[CV] END ....................max_depth=5, min_child_weight=3; total time=  21.8s\n",
      "[CV] END ....................max_depth=5, min_child_weight=4; total time=  21.7s\n",
      "[CV] END ....................max_depth=7, min_child_weight=1; total time=  26.7s\n",
      "[CV] END ....................max_depth=7, min_child_weight=1; total time=  27.2s\n",
      "[CV] END ....................max_depth=7, min_child_weight=1; total time=  29.1s\n",
      "[CV] END ....................max_depth=7, min_child_weight=1; total time=  29.2s\n",
      "[CV] END ....................max_depth=7, min_child_weight=3; total time=  17.7s\n",
      "[CV] END ....................max_depth=7, min_child_weight=2; total time=  18.3s\n",
      "[CV] END ....................max_depth=7, min_child_weight=3; total time=  19.1s\n",
      "[CV] END ....................max_depth=7, min_child_weight=2; total time=  19.4s\n",
      "[CV] END ....................max_depth=7, min_child_weight=2; total time=  19.5s\n",
      "[CV] END ....................max_depth=7, min_child_weight=2; total time=  19.9s\n",
      "[CV] END ....................max_depth=7, min_child_weight=3; total time=  15.3s\n",
      "[CV] END ....................max_depth=7, min_child_weight=1; total time=  20.6s\n",
      "[CV] END ....................max_depth=7, min_child_weight=4; total time=  15.2s\n",
      "[CV] END ....................max_depth=7, min_child_weight=4; total time=  15.3s\n",
      "[CV] END ....................max_depth=7, min_child_weight=2; total time=  21.1s\n",
      "[CV] END ....................max_depth=7, min_child_weight=4; total time=  16.3s\n",
      "[CV] END ....................max_depth=7, min_child_weight=4; total time=  17.1s\n",
      "[CV] END ....................max_depth=7, min_child_weight=3; total time=  17.7s\n",
      "[CV] END ....................max_depth=7, min_child_weight=4; total time=  17.8s\n",
      "[CV] END ....................max_depth=7, min_child_weight=3; total time=  18.2s\n",
      "{'max_depth': 7, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'max_depth': [ 2, 3, 5,  7],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5, \n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(**fixed_params),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] END ......................max_delta_step=0, subsample=9; total time=   0.2s\n",
      "[CV] END ......................max_delta_step=0, subsample=9; total time=   0.2s\n",
      "[CV] END ......................max_delta_step=0, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=0, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=0, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=0, subsample=0; total time=  11.8s\n",
      "[CV] END ......................max_delta_step=0, subsample=0; total time=  12.2s\n",
      "[CV] END ......................max_delta_step=0, subsample=0; total time=  12.3s\n",
      "[CV] END ......................max_delta_step=0, subsample=0; total time=  12.4s\n",
      "[CV] END ......................max_delta_step=0, subsample=0; total time=  12.5s\n",
      "[CV] END ......................max_delta_step=1, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=1, subsample=0; total time=  12.2s\n",
      "[CV] END ......................max_delta_step=1, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=1, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=1, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=1, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=1, subsample=0; total time=  13.6s\n",
      "[CV] END ......................max_delta_step=1, subsample=0; total time=  12.7s\n",
      "[CV] END ......................max_delta_step=1, subsample=0; total time=  12.9s\n",
      "[CV] END ......................max_delta_step=1, subsample=0; total time=  12.8s\n",
      "[CV] END ....................max_delta_step=0, subsample=1.0; total time=  30.9s\n",
      "[CV] END ....................max_delta_step=0, subsample=1.0; total time=  31.2s\n",
      "[CV] END ....................max_delta_step=0, subsample=1.0; total time=  33.8s\n",
      "[CV] END ....................max_delta_step=0, subsample=1.0; total time=  34.4s\n",
      "[CV] END ....................max_delta_step=0, subsample=1.0; total time=  34.5s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.8; total time=  34.8s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.8; total time=  35.5s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.6; total time=  35.4s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.8; total time=  35.4s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.8; total time=  35.3s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.6; total time=  36.5s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.6; total time=  36.9s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.6; total time=  36.9s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.8; total time=  36.9s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.8; total time=  37.5s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.8; total time=  37.8s\n",
      "[CV] END ......................max_delta_step=2, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=2, subsample=9; total time=   0.3s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.8; total time=  38.0s\n",
      "[CV] END ......................max_delta_step=2, subsample=9; total time=   0.2s\n",
      "[CV] END ......................max_delta_step=2, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=2, subsample=9; total time=   0.3s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.8; total time=  38.1s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.8; total time=  38.8s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.6; total time=  39.2s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.6; total time=  39.3s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.6; total time=  39.4s\n",
      "[CV] END ....................max_delta_step=0, subsample=0.6; total time=  39.6s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.6; total time=  39.2s\n",
      "[CV] END ....................max_delta_step=1, subsample=0.6; total time=  39.8s\n",
      "[CV] END ....................max_delta_step=1, subsample=1.0; total time=  29.8s\n",
      "[CV] END ....................max_delta_step=1, subsample=1.0; total time=  30.1s\n",
      "[CV] END ....................max_delta_step=1, subsample=1.0; total time=  30.4s\n",
      "[CV] END ....................max_delta_step=1, subsample=1.0; total time=  32.3s\n",
      "[CV] END ......................max_delta_step=2, subsample=0; total time=  12.4s\n",
      "[CV] END ......................max_delta_step=2, subsample=0; total time=  12.4s\n",
      "[CV] END ......................max_delta_step=2, subsample=0; total time=  12.5s\n",
      "[CV] END ......................max_delta_step=2, subsample=0; total time=  12.6s\n",
      "[CV] END ......................max_delta_step=2, subsample=0; total time=  12.5s\n",
      "[CV] END ......................max_delta_step=3, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=3, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=3, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=3, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=3, subsample=9; total time=   0.3s\n",
      "[CV] END ....................max_delta_step=1, subsample=1.0; total time=  29.9s\n",
      "[CV] END ......................max_delta_step=3, subsample=0; total time=  13.3s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.6; total time=  35.1s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.6; total time=  35.9s\n",
      "[CV] END ......................max_delta_step=3, subsample=0; total time=  12.7s\n",
      "[CV] END ......................max_delta_step=3, subsample=0; total time=  12.9s\n",
      "[CV] END ......................max_delta_step=3, subsample=0; total time=  12.3s\n",
      "[CV] END ......................max_delta_step=3, subsample=0; total time=  12.8s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.6; total time=  35.5s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.6; total time=  36.1s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.8; total time=  33.5s\n",
      "[CV] END ....................max_delta_step=2, subsample=1.0; total time=  31.8s\n",
      "[CV] END ....................max_delta_step=2, subsample=1.0; total time=  32.4s\n",
      "[CV] END ....................max_delta_step=2, subsample=1.0; total time=  32.4s\n",
      "[CV] END ....................max_delta_step=2, subsample=1.0; total time=  32.5s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.8; total time=  35.3s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.8; total time=  35.1s\n",
      "[CV] END ....................max_delta_step=2, subsample=1.0; total time=  32.3s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.8; total time=  36.8s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.8; total time=  36.8s\n",
      "[CV] END ......................max_delta_step=4, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=4, subsample=9; total time=   0.3s\n",
      "[CV] END ....................max_delta_step=2, subsample=0.6; total time=  38.3s\n",
      "[CV] END ......................max_delta_step=4, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=4, subsample=9; total time=   0.3s\n",
      "[CV] END ......................max_delta_step=4, subsample=9; total time=   0.3s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.8; total time=  36.7s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.6; total time=  37.6s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.6; total time=  37.9s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.8; total time=  36.8s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.8; total time=  34.6s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.6; total time=  38.4s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.6; total time=  38.2s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.8; total time=  34.8s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.6; total time=  39.0s\n",
      "[CV] END ....................max_delta_step=3, subsample=0.8; total time=  34.9s\n",
      "[CV] END ......................max_delta_step=4, subsample=0; total time=   9.6s\n",
      "[CV] END ....................max_delta_step=3, subsample=1.0; total time=  30.4s\n",
      "[CV] END ......................max_delta_step=4, subsample=0; total time=  11.6s\n",
      "[CV] END ......................max_delta_step=4, subsample=0; total time=  12.4s\n",
      "[CV] END ......................max_delta_step=4, subsample=0; total time=  12.4s\n",
      "[CV] END ......................max_delta_step=4, subsample=0; total time=  12.2s\n",
      "[CV] END ....................max_delta_step=3, subsample=1.0; total time=  29.6s\n",
      "[CV] END ....................max_delta_step=3, subsample=1.0; total time=  26.2s\n",
      "[CV] END ....................max_delta_step=3, subsample=1.0; total time=  26.5s\n",
      "[CV] END ....................max_delta_step=3, subsample=1.0; total time=  28.7s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.6; total time=  29.4s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.8; total time=  24.0s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.6; total time=  30.1s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.6; total time=  30.4s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.6; total time=  25.1s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.6; total time=  29.5s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.8; total time=  23.2s\n",
      "[CV] END ....................max_delta_step=4, subsample=1.0; total time=  20.3s\n",
      "[CV] END ....................max_delta_step=4, subsample=1.0; total time=  20.4s\n",
      "[CV] END ....................max_delta_step=4, subsample=1.0; total time=  16.9s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.8; total time=  24.6s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.8; total time=  23.0s\n",
      "[CV] END ....................max_delta_step=4, subsample=0.8; total time=  23.5s\n",
      "[CV] END ....................max_delta_step=4, subsample=1.0; total time=  17.3s\n",
      "[CV] END ....................max_delta_step=4, subsample=1.0; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 9 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.37060696 0.36868293 0.11140159        nan 0.36507527 0.36928465\n",
      " 0.37055152 0.11140159        nan 0.36183658 0.36949455 0.36873044\n",
      " 0.11140159        nan 0.36520689 0.36988681 0.36868293 0.11140159\n",
      "        nan 0.36507527 0.36988681 0.36868293 0.11140159        nan\n",
      " 0.36507527]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_delta_step': 0, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'subsample': [0.6, 0.8, 0.9, 1.0],\n",
    "    'max_delta_step': [0, 1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(**fixed_params),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:17:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.9196\n",
      "Validation F1 Score: 0.3822\n",
      "Training Accuracy: 0.9327\n",
      "Validation Accuracy: 0.5550\n"
     ]
    }
   ],
   "source": [
    "final_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.6,\n",
    "    'max_delta_step': 0,\n",
    "    'random_state': seed,\n",
    "    'class_weight': {0: 0.2, 1: 0.6, 2: 0.2}\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(**final_params)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_preds = xgb_model.predict(X_train)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "valid_preds = xgb_model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# Display the F1 scores\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:17:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training Accuracy: 0.9493\n",
      "Training F1 Score: 0.9402\n",
      "Validation Accuracy: 0.5505\n",
      "Validation F1 Score: 0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "Training Accuracy: 0.9483\n",
      "Training F1 Score: 0.9389\n",
      "Validation Accuracy: 0.5525\n",
      "Validation F1 Score: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "Training Accuracy: 0.9482\n",
      "Training F1 Score: 0.9388\n",
      "Validation Accuracy: 0.5586\n",
      "Validation F1 Score: 0.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "Training Accuracy: 0.9482\n",
      "Training F1 Score: 0.9388\n",
      "Validation Accuracy: 0.5586\n",
      "Validation F1 Score: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n",
      "Training Accuracy: 0.9467\n",
      "Training F1 Score: 0.9369\n",
      "Validation Accuracy: 0.5592\n",
      "Validation F1 Score: 0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6\n",
      "Training Accuracy: 0.9486\n",
      "Training F1 Score: 0.9393\n",
      "Validation Accuracy: 0.5577\n",
      "Validation F1 Score: 0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7\n",
      "Training Accuracy: 0.9488\n",
      "Training F1 Score: 0.9395\n",
      "Validation Accuracy: 0.5523\n",
      "Validation F1 Score: 0.3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:34] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8\n",
      "Training Accuracy: 0.9481\n",
      "Training F1 Score: 0.9386\n",
      "Validation Accuracy: 0.5532\n",
      "Validation F1 Score: 0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9\n",
      "Training Accuracy: 0.9496\n",
      "Training F1 Score: 0.9406\n",
      "Validation Accuracy: 0.5530\n",
      "Validation F1 Score: 0.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:18:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.167.135/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m acc \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.167.135/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m (train, test), i  \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(cv\u001b[39m.\u001b[39msplit(X_train, y_train), \u001b[39mrange\u001b[39m(n_splits)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.167.135/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     xgb\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49miloc[train], y_train\u001b[39m.\u001b[39;49miloc[train])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.167.135/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     train_preds \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(X_train\u001b[39m.\u001b[39miloc[train])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.167.135/export/home/darpan/work_dir/FOML_hkthn/src/xgboost.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     valid_preds \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(X_train\u001b[39m.\u001b[39miloc[test])\n",
      "File \u001b[0;32m~/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1532\u001b[0m     params,\n\u001b[1;32m   1533\u001b[0m     train_dmatrix,\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1535\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1536\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1537\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1538\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1539\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1540\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1541\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1542\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[1;32m   1543\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, iteration\u001b[39m=\u001b[39;49mi, fobj\u001b[39m=\u001b[39;49mobj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_1/lib/python3.11/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2102\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2103\u001b[0m         )\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBClassifier(**final_params)\n",
    "\n",
    "f1 = []\n",
    "acc = []\n",
    "\n",
    "for (train, test), i  in zip(cv.split(X_train, y_train), range(n_splits)):\n",
    "    xgb.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "\n",
    "    train_preds = xgb.predict(X_train.iloc[train])\n",
    "    valid_preds = xgb.predict(X_train.iloc[test])\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train.iloc[train], train_preds)\n",
    "    train_f1 = f1_score(y_train.iloc[train], train_preds, average='macro')\n",
    "\n",
    "    valid_accuracy = accuracy_score(y_train.iloc[test], valid_preds)\n",
    "    valid_f1 = f1_score(y_train.iloc[test], valid_preds, average='macro')\n",
    "\n",
    "    f1.append(valid_f1)\n",
    "    acc.append(valid_accuracy)\n",
    "\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score: {valid_f1:.4f}\") \n",
    "\n",
    "print(f\"Mean F1 Score: {np.mean(f1):.4f}\")\n",
    "print(f\"Mean Accuracy: {np.mean(acc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_preds = xgb.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('../data/output/xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "medium    7063\n",
      "low       4511\n",
      "high      4347\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# unique values in the test predictions\n",
    "print(submission['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for num_samples_m = 1.2 * num_samples, on trian               \n",
    "Params: -               \n",
    "final_params = {\n",
    "    'n_estimators': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.8,\n",
    "    'max_delta_step': 1,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "- for num_samples_m = * num_samples, on train               \n",
    "Params: -                   \n",
    "final_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 1.0,\n",
    "    'max_delta_step': 0,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "- for num_samples_m = 0.85 * num_samples, on train               \n",
    "Params: -          (got 0.400 score)          \n",
    "final_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'max_delta_step': 1,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "- for num_samples_m = num_samples, on train , CorrDrop data        \n",
    "Params: -               \n",
    "final_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.6,\n",
    "    'max_delta_step': 1,\n",
    "    'random_state': seed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
