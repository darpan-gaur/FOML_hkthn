{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# train_data = pd.read_csv('../data/preprocessed_train.csv')\n",
    "# test_data = pd.read_csv('../data/preprocessed_test.csv')\n",
    "\n",
    "# train_data = pd.read_csv('../data/preprocessed_train_CorrDrop.csv')\n",
    "# test_data = pd.read_csv('../data/preprocessed_test_CorrDrop.csv')\n",
    "\n",
    "train_data = pd.read_csv('../data/preprocessed_train_KNNim.csv')\n",
    "test_data = pd.read_csv('../data/preprocessed_test_KNNim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'UID' column as the index\n",
    "train_data.set_index('UID', inplace=True)\n",
    "\n",
    "# Set the 'UID' column as the index\n",
    "test_data.set_index('UID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for 'Target' column\n",
    "target_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "# Apply the mapping to the 'Target' column\n",
    "train_labels = train_data['Target'].map(target_mapping)\n",
    "\n",
    "# Drop the 'Target' column from the training data\n",
    "train_data = train_data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "0    22514\n",
      "1    22514\n",
      "2    22514\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# make train data with 22514 data of each class\n",
    "\n",
    "# Separate the data based on the target classes\n",
    "low_class = train_data[train_labels == 0]\n",
    "medium_class = train_data[train_labels == 1]\n",
    "high_class = train_data[train_labels == 2]\n",
    "\n",
    "# Get the number of samples in each class\n",
    "low_class_count = len(low_class)\n",
    "medium_class_count = len(medium_class)\n",
    "high_class_count = len(high_class)\n",
    "\n",
    "# Set the number of samples to be selected from each class\n",
    "num_samples = min(low_class_count, medium_class_count, high_class_count)\n",
    "num_samples_m = int(num_samples*1.0)\n",
    "\n",
    "# Randomly sample data from each class\n",
    "low_class_sample = low_class.sample(n=num_samples, random_state=seed)\n",
    "medium_class_sample = medium_class.sample(n=num_samples_m, random_state=seed)\n",
    "high_class_sample = high_class.sample(n=num_samples, random_state=seed)\n",
    "\n",
    "# Concatenate the sampled data\n",
    "train_data_sampled = pd.concat([low_class_sample, medium_class_sample, high_class_sample])\n",
    "\n",
    "# Separate the features and target variable\n",
    "X_sampled = train_data_sampled\n",
    "y_sampled = train_labels.loc[train_data_sampled.index]\n",
    "\n",
    "# Display the count of unique values in the target variable\n",
    "print(y_sampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112569, 20)\n",
      "X_valid shape: (112569, 20)\n",
      "y_train shape: (112569,)\n",
      "y_valid shape: (112569,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_labels, test_size=0.1, random_state=seed)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_sampled, y_sampled, test_size=0.1, random_state=seed)\n",
    "# X_train, y_train = X_sampled, y_sampled\n",
    "# X_valid, y_valid = X_sampled, y_sampled\n",
    "X_train, y_train = train_data, train_labels\n",
    "X_valid, y_valid = train_data, train_labels\n",
    "\n",
    "# Display the shapes of the training and validation sets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5428\n",
      "Training F1 Score: 0.5001\n",
      "Validation Accuracy: 0.5428\n",
      "Validation F1 Score: 0.5001\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=5,\n",
    "    max_depth=10,\n",
    "    bootstrap=False,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1, \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy and F1 score on the training set\n",
    "train_preds = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "# Accuracy and F1 score on the validation set\n",
    "valid_preds = rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# Display the accuracy and F1 score\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FieldEstablishedYear         0.147896\n",
      "RawLocationId                0.096179\n",
      "Longitude                    0.092435\n",
      "TotalCultivatedAreaSqft      0.092296\n",
      "TotalTaxAssessed             0.080653\n",
      "Latitude                     0.076342\n",
      "CultivatedAreaSqft1          0.072891\n",
      "TotalValue                   0.060725\n",
      "TaxAgrarianValue             0.055471\n",
      "TaxLandValue                 0.052411\n",
      "AgricultureZoningCode        0.029981\n",
      "AgriculturalPostalZone       0.029967\n",
      "WaterAccessPoints            0.023298\n",
      "WaterAccessPointsCalc        0.020809\n",
      "LandUsageType                0.017668\n",
      "CropSpeciesVariety           0.014238\n",
      "NationalRegionCode           0.011700\n",
      "MainIrrigationSystemCount    0.010657\n",
      "StorageAndFacilityCount      0.008449\n",
      "ValuationYear                0.005934\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# faeture importance\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_importances = pd.Series(feature_importances, index=X_train.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "# Display \n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training Accuracy: 0.5371\n",
      "Training F1 Score: 0.4993\n",
      "Validation Accuracy: 0.4789\n",
      "Validation F1 Score: 0.4256\n",
      "Fold 2\n",
      "Training Accuracy: 0.5438\n",
      "Training F1 Score: 0.5034\n",
      "Validation Accuracy: 0.4721\n",
      "Validation F1 Score: 0.4185\n",
      "Fold 3\n",
      "Training Accuracy: 0.5456\n",
      "Training F1 Score: 0.5043\n",
      "Validation Accuracy: 0.4817\n",
      "Validation F1 Score: 0.4230\n",
      "Fold 4\n",
      "Training Accuracy: 0.5467\n",
      "Training F1 Score: 0.5047\n",
      "Validation Accuracy: 0.4833\n",
      "Validation F1 Score: 0.4278\n",
      "Fold 5\n",
      "Training Accuracy: 0.5467\n",
      "Training F1 Score: 0.5053\n",
      "Validation Accuracy: 0.4812\n",
      "Validation F1 Score: 0.4237\n",
      "Fold 6\n",
      "Training Accuracy: 0.5429\n",
      "Training F1 Score: 0.5028\n",
      "Validation Accuracy: 0.4909\n",
      "Validation F1 Score: 0.4380\n",
      "Fold 7\n",
      "Training Accuracy: 0.5466\n",
      "Training F1 Score: 0.5032\n",
      "Validation Accuracy: 0.4848\n",
      "Validation F1 Score: 0.4293\n",
      "Fold 8\n",
      "Training Accuracy: 0.5440\n",
      "Training F1 Score: 0.5038\n",
      "Validation Accuracy: 0.4807\n",
      "Validation F1 Score: 0.4246\n",
      "Fold 9\n",
      "Training Accuracy: 0.5473\n",
      "Training F1 Score: 0.5052\n",
      "Validation Accuracy: 0.4905\n",
      "Validation F1 Score: 0.4335\n",
      "Fold 10\n",
      "Training Accuracy: 0.5422\n",
      "Training F1 Score: 0.5024\n",
      "Validation Accuracy: 0.4836\n",
      "Validation F1 Score: 0.4303\n",
      "Mean F1 Score: 0.4274\n",
      "Mean Accuracy: 0.4828\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=5,\n",
    "    max_depth=10,\n",
    "    bootstrap=False,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1, \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "f1 = []\n",
    "acc = []\n",
    "\n",
    "for (train, test), i  in zip(cv.split(X_train, y_train), range(n_splits)):\n",
    "    rf.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "\n",
    "    train_preds = rf.predict(X_train.iloc[train])\n",
    "    valid_preds = rf.predict(X_train.iloc[test])\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train.iloc[train], train_preds)\n",
    "    train_f1 = f1_score(y_train.iloc[train], train_preds, average='macro')\n",
    "\n",
    "    valid_accuracy = accuracy_score(y_train.iloc[test], valid_preds)\n",
    "    valid_f1 = f1_score(y_train.iloc[test], valid_preds, average='macro')\n",
    "\n",
    "    f1.append(valid_f1)\n",
    "    acc.append(valid_accuracy)\n",
    "\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score: {valid_f1:.4f}\") \n",
    "\n",
    "print(f\"Mean F1 Score: {np.mean(f1):.4f}\")\n",
    "print(f\"Mean Accuracy: {np.mean(acc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = rf.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('../data/output/randomForest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "# Initialize the Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/export/home/darpan/anaconda3/envs/env_1/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.35624797 0.35129157 0.34504704 0.34810835 0.34736115 0.34273572\n",
      " 0.33796864 0.33796864 0.33677366        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.35172922 0.34984715 0.34348372 0.34495215 0.34430932 0.34010692\n",
      " 0.33344425 0.33344425 0.33341023 0.35172922 0.34984715 0.34348372\n",
      " 0.3449762  0.34430932 0.34010692 0.33344425 0.33344425 0.33341023]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [5, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    random_state=seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Initialize the Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Training F1 Score: 1.0000\n",
      "Validation Accuracy: 1.0000\n",
      "Validation F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy and F1 score on the training set\n",
    "train_preds = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "# Accuracy and F1 score on the validation set\n",
    "valid_preds = rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# Display the accuracy and F1 score\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = rf.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('../data/output/randomForest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium    9275\n",
      "low       3496\n",
      "high      3150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# unique values in test predictions\n",
    "print(test_preds.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
