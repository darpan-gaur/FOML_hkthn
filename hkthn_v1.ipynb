{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>AgriculturalPostalZone</th>\n",
       "      <th>AgricultureZoningCode</th>\n",
       "      <th>CropFieldConfiguration</th>\n",
       "      <th>CropSpeciesVariety</th>\n",
       "      <th>CultivatedAndWildArea</th>\n",
       "      <th>CultivatedAreaSqft1</th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>FarmClassification</th>\n",
       "      <th>FarmEquipmentArea</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalTaxAssessed</th>\n",
       "      <th>TotalValue</th>\n",
       "      <th>TownId</th>\n",
       "      <th>TypeOfIrrigationSystem</th>\n",
       "      <th>UndergroundStorageSqft</th>\n",
       "      <th>ValuationYear</th>\n",
       "      <th>WaterAccessPoints</th>\n",
       "      <th>WaterAccessPointsCalc</th>\n",
       "      <th>WaterReservoirCount</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12998</td>\n",
       "      <td>291674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8636.716</td>\n",
       "      <td>456255.6</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20860</td>\n",
       "      <td>164397</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18464.292</td>\n",
       "      <td>996887.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75725</td>\n",
       "      <td>616532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>922.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15594.568</td>\n",
       "      <td>1043780.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106521</td>\n",
       "      <td>942111</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8494.618</td>\n",
       "      <td>435734.8</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99467</td>\n",
       "      <td>475557</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13517.284</td>\n",
       "      <td>885400.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID  AgriculturalPostalZone  AgricultureZoningCode  \\\n",
       "0   12998                  291674                    0.0   \n",
       "1   20860                  164397                   28.0   \n",
       "2   75725                  616532                    0.0   \n",
       "3  106521                  942111                   43.0   \n",
       "4   99467                  475557                   38.0   \n",
       "\n",
       "   CropFieldConfiguration  CropSpeciesVariety  CultivatedAndWildArea  \\\n",
       "0                     NaN                 3.0                    NaN   \n",
       "1                     NaN                 4.0                    NaN   \n",
       "2                     NaN                 2.0                    NaN   \n",
       "3                     NaN                 7.0                    NaN   \n",
       "4                     NaN                 3.0                    NaN   \n",
       "\n",
       "   CultivatedAreaSqft1  DistrictId  FarmClassification  FarmEquipmentArea  \\\n",
       "0               1136.0         1.0                 NaN                NaN   \n",
       "1               2083.0         1.0                 NaN                NaN   \n",
       "2                922.0         1.0                 NaN                NaN   \n",
       "3                  NaN         1.0                 NaN                NaN   \n",
       "4               2225.0         3.0                 NaN                0.0   \n",
       "\n",
       "   ...  TotalTaxAssessed  TotalValue  TownId  TypeOfIrrigationSystem  \\\n",
       "0  ...          8636.716    456255.6   118.0                     NaN   \n",
       "1  ...         18464.292    996887.6    24.0                     1.0   \n",
       "2  ...         15594.568   1043780.0     9.0                     1.0   \n",
       "3  ...          8494.618    435734.8   114.0                     NaN   \n",
       "4  ...         13517.284    885400.0     6.0                     NaN   \n",
       "\n",
       "   UndergroundStorageSqft  ValuationYear  WaterAccessPoints  \\\n",
       "0                     NaN         2018.0                2.0   \n",
       "1                     NaN         2018.0                3.0   \n",
       "2                     NaN         2018.0                1.0   \n",
       "3                     NaN         2020.0                3.0   \n",
       "4                     NaN         2020.0                4.0   \n",
       "\n",
       "   WaterAccessPointsCalc  WaterReservoirCount  Target  \n",
       "0                    2.0                  NaN    high  \n",
       "1                    3.0                  1.0  medium  \n",
       "2                    1.0                  NaN  medium  \n",
       "3                    3.0                  NaN     low  \n",
       "4                    4.0                  NaN  medium  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Column  MissingCount  MissingPercentage\n",
      "0             FarmClassification        112552          99.984898\n",
      "1       PerimeterGuardPlantsArea        112525          99.960913\n",
      "2         UndergroundStorageSqft        112512          99.949364\n",
      "3                 FieldZoneLevel        112512          99.949364\n",
      "4             HarvestStorageSqft        112457          99.900505\n",
      "5                  HasGreenHouse        112305          99.765477\n",
      "6         CropFieldConfiguration        112274          99.737939\n",
      "7          FieldConstructionType        112239          99.706846\n",
      "8          CultivatedAndWildArea        112027          99.518518\n",
      "9                FieldShadeCover        111701          99.228917\n",
      "10                 ReservoirType        111477          99.029928\n",
      "11            TotalReservoirSize        111332          98.901118\n",
      "12           ReservoirWithFilter        111032          98.634615\n",
      "13                HasPestControl        109940          97.664544\n",
      "14                TaxOverdueYear        109516          97.287886\n",
      "15              TaxOverdueStatus        109516          97.287886\n",
      "16              FarmShedAreaSqft        109168          96.978742\n",
      "17                 TotalAreaSqft        108214          96.131262\n",
      "18           PrimaryCropAreaSqft        103876          92.277625\n",
      "19          PrimaryCropAreaSqft2        103876          92.277625\n",
      "20             NumberGreenHouses        100472          89.253702\n",
      "21  PartialIrrigationSystemCount         97520          86.631311\n",
      "22           NaturalLakePresence         90955          80.799332\n",
      "23           WaterReservoirCount         89405          79.422399\n",
      "24          NumberOfFarmingZones         86959          77.249509\n",
      "25        TypeOfIrrigationSystem         76133          67.632297\n",
      "26             FarmEquipmentArea         75225          66.825680\n",
      "27              FarmVehicleCount         75225          66.825680\n",
      "28               OtherZoningCode         71504          63.520152\n",
      "29            FarmingCommunityId         67885          60.305235\n",
      "30         HarvestProcessingType         41773          37.108795\n",
      "31             SoilFertilityType         40801          36.245325\n",
      "32              FarmingUnitCount         39565          35.147332\n",
      "33                 FieldSizeSqft         12309          10.934627\n",
      "34           CultivatedAreaSqft1          5521           4.904547\n",
      "35                        TownId          2257           2.004992\n",
      "36         WaterAccessPointsCalc          1193           1.059794\n",
      "37     MainIrrigationSystemCount          1193           1.059794\n",
      "38          FieldEstablishedYear           684           0.607627\n",
      "39       TotalCultivatedAreaSqft           580           0.515240\n",
      "40                    TotalValue           330           0.293154\n",
      "41              TaxAgrarianValue           330           0.293154\n",
      "42         AgricultureZoningCode           134           0.119038\n",
      "43              TotalTaxAssessed            28           0.024874\n",
      "44                  TaxLandValue            21           0.018655\n",
      "45                 ValuationYear            20           0.017767\n",
      "46            NationalRegionCode            20           0.017767\n",
      "47       StorageAndFacilityCount            20           0.017767\n",
      "48                 RawLocationId            20           0.017767\n",
      "49                     Longitude            20           0.017767\n",
      "50                      Latitude            20           0.017767\n",
      "51                 LandUsageType            20           0.017767\n",
      "52                    DistrictId            20           0.017767\n",
      "53            CropSpeciesVariety            20           0.017767\n",
      "54             WaterAccessPoints            20           0.017767\n",
      "55                           UID             0           0.000000\n",
      "56        AgriculturalPostalZone             0           0.000000\n",
      "57                        Target             0           0.000000\n"
     ]
    }
   ],
   "source": [
    "# Count missing values for each column\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# Create a DataFrame to store the count of missing values\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'MissingCount': missing_values.values\n",
    "})\n",
    "\n",
    "# Add a column to show the percentage of missing values\n",
    "missing_df['MissingPercentage'] = (missing_df['MissingCount'] / len(train_data)) * 100\n",
    "\n",
    "# Sort the DataFrame by the number of missing values in descending order\n",
    "missing_df.sort_values(by='MissingCount', ascending=False, inplace=True)\n",
    "\n",
    "# Reset index for readability\n",
    "missing_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- null rate for dropping set to > 60%.\n",
    "- Try 30% and 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated shape of the DataFrame: (112569, 24)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing percentage greater than 60%\n",
    "columns_to_drop = missing_df[missing_df['MissingPercentage'] > 10]['Column'].tolist()\n",
    "\n",
    "# Drop the identified columns from the DataFrame\n",
    "train_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame shape after dropping columns\n",
    "print(f\"Updated shape of the DataFrame: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated shape of the DataFrame: (15921, 23)\n"
     ]
    }
   ],
   "source": [
    "# drop same columns from test data\n",
    "test_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame shape after dropping columns\n",
    "print(f\"Updated shape of the DataFrame: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgriculturalPostalZone</th>\n",
       "      <th>AgricultureZoningCode</th>\n",
       "      <th>CropSpeciesVariety</th>\n",
       "      <th>CultivatedAreaSqft1</th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>FieldEstablishedYear</th>\n",
       "      <th>LandUsageType</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MainIrrigationSystemCount</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxAgrarianValue</th>\n",
       "      <th>TaxLandValue</th>\n",
       "      <th>TotalCultivatedAreaSqft</th>\n",
       "      <th>TotalTaxAssessed</th>\n",
       "      <th>TotalValue</th>\n",
       "      <th>TownId</th>\n",
       "      <th>ValuationYear</th>\n",
       "      <th>WaterAccessPoints</th>\n",
       "      <th>WaterAccessPointsCalc</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>291674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.466018e+07</td>\n",
       "      <td>7.850723e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81652.8</td>\n",
       "      <td>374602.8</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>8636.716</td>\n",
       "      <td>456255.6</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20860</th>\n",
       "      <td>164397</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.436794e+07</td>\n",
       "      <td>7.911895e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>323700.8</td>\n",
       "      <td>673186.8</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>18464.292</td>\n",
       "      <td>996887.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75725</th>\n",
       "      <td>616532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.455721e+07</td>\n",
       "      <td>7.864265e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87440.0</td>\n",
       "      <td>956340.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>15594.568</td>\n",
       "      <td>1043780.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106521</th>\n",
       "      <td>942111</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.433931e+07</td>\n",
       "      <td>7.868407e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134075.2</td>\n",
       "      <td>301659.6</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>8494.618</td>\n",
       "      <td>435734.8</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99467</th>\n",
       "      <td>475557</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.456592e+07</td>\n",
       "      <td>7.770447e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>741400.0</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>13517.284</td>\n",
       "      <td>885400.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AgriculturalPostalZone  AgricultureZoningCode  CropSpeciesVariety  \\\n",
       "UID                                                                         \n",
       "12998                   291674                    0.0                 3.0   \n",
       "20860                   164397                   28.0                 4.0   \n",
       "75725                   616532                    0.0                 2.0   \n",
       "106521                  942111                   43.0                 7.0   \n",
       "99467                   475557                   38.0                 3.0   \n",
       "\n",
       "        CultivatedAreaSqft1  DistrictId  FieldEstablishedYear  LandUsageType  \\\n",
       "UID                                                                            \n",
       "12998                1136.0         1.0                1926.0            1.0   \n",
       "20860                2083.0         1.0                1981.0            1.0   \n",
       "75725                 922.0         1.0                1931.0            1.0   \n",
       "106521                  NaN         1.0                1964.0            8.0   \n",
       "99467                2225.0         3.0                2009.0            2.0   \n",
       "\n",
       "            Latitude     Longitude  MainIrrigationSystemCount  ...  \\\n",
       "UID                                                            ...   \n",
       "12998   2.466018e+07  7.850723e+07                        2.0  ...   \n",
       "20860   2.436794e+07  7.911895e+07                        3.0  ...   \n",
       "75725   2.455721e+07  7.864265e+07                        1.0  ...   \n",
       "106521  2.433931e+07  7.868407e+07                        3.0  ...   \n",
       "99467   2.456592e+07  7.770447e+07                        4.0  ...   \n",
       "\n",
       "        TaxAgrarianValue  TaxLandValue  TotalCultivatedAreaSqft  \\\n",
       "UID                                                               \n",
       "12998            81652.8      374602.8                   1136.0   \n",
       "20860           323700.8      673186.8                   2083.0   \n",
       "75725            87440.0      956340.0                    922.0   \n",
       "106521          134075.2      301659.6                   3202.0   \n",
       "99467           144000.0      741400.0                   2225.0   \n",
       "\n",
       "        TotalTaxAssessed  TotalValue  TownId  ValuationYear  \\\n",
       "UID                                                           \n",
       "12998           8636.716    456255.6   118.0         2018.0   \n",
       "20860          18464.292    996887.6    24.0         2018.0   \n",
       "75725          15594.568   1043780.0     9.0         2018.0   \n",
       "106521          8494.618    435734.8   114.0         2020.0   \n",
       "99467          13517.284    885400.0     6.0         2020.0   \n",
       "\n",
       "        WaterAccessPoints  WaterAccessPointsCalc  Target  \n",
       "UID                                                       \n",
       "12998                 2.0                    2.0    high  \n",
       "20860                 3.0                    3.0  medium  \n",
       "75725                 1.0                    1.0  medium  \n",
       "106521                3.0                    3.0     low  \n",
       "99467                 4.0                    4.0  medium  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the 'UID' column as the index\n",
    "train_data.set_index('UID', inplace=True)\n",
    "\n",
    "# Display the updated DataFrame to confirm the change\n",
    "# print(train_data.head())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgriculturalPostalZone</th>\n",
       "      <th>AgricultureZoningCode</th>\n",
       "      <th>CropSpeciesVariety</th>\n",
       "      <th>CultivatedAreaSqft1</th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>FieldEstablishedYear</th>\n",
       "      <th>LandUsageType</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MainIrrigationSystemCount</th>\n",
       "      <th>...</th>\n",
       "      <th>StorageAndFacilityCount</th>\n",
       "      <th>TaxAgrarianValue</th>\n",
       "      <th>TaxLandValue</th>\n",
       "      <th>TotalCultivatedAreaSqft</th>\n",
       "      <th>TotalTaxAssessed</th>\n",
       "      <th>TotalValue</th>\n",
       "      <th>TownId</th>\n",
       "      <th>ValuationYear</th>\n",
       "      <th>WaterAccessPoints</th>\n",
       "      <th>WaterAccessPointsCalc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130000</th>\n",
       "      <td>475712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.503083e+07</td>\n",
       "      <td>7.869366e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166216.0</td>\n",
       "      <td>153157.4</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>9540.432</td>\n",
       "      <td>319373.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129101</th>\n",
       "      <td>101762</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.464948e+07</td>\n",
       "      <td>7.776945e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>132000.0</td>\n",
       "      <td>673200.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>11064.284</td>\n",
       "      <td>805200.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147876</th>\n",
       "      <td>309344</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.416257e+07</td>\n",
       "      <td>7.880234e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98530.4</td>\n",
       "      <td>207336.8</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>5789.762</td>\n",
       "      <td>305867.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122624</th>\n",
       "      <td>689775</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.437655e+07</td>\n",
       "      <td>7.888689e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135032.8</td>\n",
       "      <td>389565.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>9440.486</td>\n",
       "      <td>524597.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159920</th>\n",
       "      <td>445333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.402429e+07</td>\n",
       "      <td>7.911369e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59100.8</td>\n",
       "      <td>633872.8</td>\n",
       "      <td>768.0</td>\n",
       "      <td>8384.640</td>\n",
       "      <td>692973.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AgriculturalPostalZone  AgricultureZoningCode  CropSpeciesVariety  \\\n",
       "UID                                                                         \n",
       "130000                  475712                    0.0                 5.0   \n",
       "129101                  101762                   46.0                 3.0   \n",
       "147876                  309344                   19.0                 2.0   \n",
       "122624                  689775                   19.0                 3.0   \n",
       "159920                  445333                   20.0                 1.0   \n",
       "\n",
       "        CultivatedAreaSqft1  DistrictId  FieldEstablishedYear  LandUsageType  \\\n",
       "UID                                                                            \n",
       "130000               2870.0         1.0                2009.0            1.0   \n",
       "129101               1291.0         3.0                1975.0            1.0   \n",
       "147876               1074.0         1.0                1970.0            2.0   \n",
       "122624               1595.0         1.0                1979.0            2.0   \n",
       "159920                768.0         2.0                1985.0            2.0   \n",
       "\n",
       "            Latitude     Longitude  MainIrrigationSystemCount  ...  \\\n",
       "UID                                                            ...   \n",
       "130000  2.503083e+07  7.869366e+07                        3.0  ...   \n",
       "129101  2.464948e+07  7.776945e+07                        2.0  ...   \n",
       "147876  2.416257e+07  7.880234e+07                        2.0  ...   \n",
       "122624  2.437655e+07  7.888689e+07                        2.0  ...   \n",
       "159920  2.402429e+07  7.911369e+07                        1.0  ...   \n",
       "\n",
       "        StorageAndFacilityCount  TaxAgrarianValue  TaxLandValue  \\\n",
       "UID                                                               \n",
       "130000                      0.0          166216.0      153157.4   \n",
       "129101                      5.0          132000.0      673200.0   \n",
       "147876                      0.0           98530.4      207336.8   \n",
       "122624                      0.0          135032.8      389565.0   \n",
       "159920                      0.0           59100.8      633872.8   \n",
       "\n",
       "        TotalCultivatedAreaSqft  TotalTaxAssessed  TotalValue  TownId  \\\n",
       "UID                                                                     \n",
       "130000                   2870.0          9540.432    319373.4    52.0   \n",
       "129101                   1291.0         11064.284    805200.0    47.0   \n",
       "147876                   1074.0          5789.762    305867.2    14.0   \n",
       "122624                   1595.0          9440.486    524597.8     NaN   \n",
       "159920                    768.0          8384.640    692973.6    10.0   \n",
       "\n",
       "        ValuationYear  WaterAccessPoints  WaterAccessPointsCalc  \n",
       "UID                                                              \n",
       "130000         2020.0                3.0                    3.0  \n",
       "129101         2020.0                2.0                    2.0  \n",
       "147876         2020.0                2.0                    2.0  \n",
       "122624         2020.0                2.0                    2.0  \n",
       "159920         2020.0                1.0                    1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the 'UID' column as the index\n",
    "test_data.set_index('UID', inplace=True)\n",
    "\n",
    "# Display the updated DataFrame to confirm the change\n",
    "# print(test_data.head())\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID\n",
      "12998     2\n",
      "20860     1\n",
      "75725     1\n",
      "106521    0\n",
      "99467     1\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping for 'Target' column\n",
    "target_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "# Apply the mapping to the 'Target' column\n",
    "train_labels = train_data['Target'].map(target_mapping)\n",
    "\n",
    "# Display the first few rows of the labels to verify the mapping\n",
    "print(train_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['TownId','Target','DistrictId'])\n",
    "\n",
    "test_data = test_data.drop(columns=['TownId','DistrictId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling:\n",
      " Series([], dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15481/3586585803.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_values(df):\n",
    "    # Define the columns based on their type\n",
    "    categorical_columns = [\n",
    "        'HarvestProcessingType', 'SoilFertilityType', 'AgricultureZoningCode',\n",
    "        'ValuationYear', 'NationalRegionCode', 'StorageAndFacilityCount', 'RawLocationId',\n",
    "        'LandUsageType', 'CropSpeciesVariety', 'AgriculturalPostalZone'\n",
    "    ]\n",
    "    \n",
    "    median_columns = [\n",
    "        'FarmingUnitCount', 'FieldSizeSqft', 'CultivatedAreaSqft1', 'MainIrrigationSystemCount',\n",
    "        'FieldEstablishedYear', 'TotalTaxAssessed', 'TaxLandValue', 'TotalCultivatedAreaSqft',\n",
    "        'WaterAccessPoints', 'TaxAgrarianValue', 'TotalValue'\n",
    "    ]\n",
    "    \n",
    "    mean_columns = [\n",
    "        'WaterAccessPointsCalc', 'Longitude', 'Latitude'\n",
    "    ]\n",
    "    \n",
    "    # Convert categorical columns to 'object' type if necessary\n",
    "    for column in categorical_columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype('object')\n",
    "\n",
    "    # Fill missing values for categorical columns using mode\n",
    "    for column in categorical_columns:\n",
    "        if column in df.columns:\n",
    "            if df[column].isnull().sum() > 0:\n",
    "                try:\n",
    "                    mode_value = df[column].mode(dropna=True)[0] if not df[column].mode().empty else None\n",
    "                    if mode_value is not None:\n",
    "                        df[column].fillna(mode_value, inplace=True)\n",
    "                    else:\n",
    "                        print(f\"Warning: Could not find a mode for column {column}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error while filling mode for column {column}: {e}\")\n",
    "    \n",
    "    # Fill missing values for numerical columns using median\n",
    "    for column in median_columns:\n",
    "        if column in df.columns and df[column].dtype in ['int64', 'float64']:\n",
    "            if df[column].isnull().sum() > 0:\n",
    "                median_value = df[column].median()\n",
    "                df[column].fillna(median_value, inplace=True)\n",
    "    \n",
    "    # Fill missing values for numerical columns using mean\n",
    "    for column in mean_columns:\n",
    "        if column in df.columns and df[column].dtype in ['int64', 'float64']:\n",
    "            if df[column].isnull().sum() > 0:\n",
    "                mean_value = df[column].mean()\n",
    "                df[column].fillna(mean_value, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fill missing values in the training data\n",
    "train_data = fill_missing_values(train_data)\n",
    "\n",
    "# Check if there are still missing values\n",
    "missing_values = train_data.isnull().sum()\n",
    "print(\"Missing values after filling:\\n\", missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15481/3586585803.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[column].fillna(mode_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_15481/3586585803.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill missing values in test data\n",
    "test_data = fill_missing_values(test_data)\n",
    "\n",
    "# Check if there are still missing values\n",
    "missing_values = test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Agriculturepostalzone to int\n",
    "train_data['AgriculturalPostalZone'] = train_data['AgriculturalPostalZone'].astype(int)\n",
    "test_data['AgriculturalPostalZone'] = test_data['AgriculturalPostalZone'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({1: 67541, 2: 22514, 0: 22514})\n",
      "After SMOTE: Counter({2: 67541, 1: 67541, 0: 67541})\n"
     ]
    }
   ],
   "source": [
    "# sampling imbalance class with SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(train_labels)\n",
    "print(f\"Before SMOTE: {counter}\")\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=seed)\n",
    "\n",
    "train_data, train_labels = smote.fit_resample(train_data, train_labels)\n",
    "counter = collections.Counter(train_labels)\n",
    "print(f\"After SMOTE: {counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Feature  Importance\n",
      "0      AgriculturalPostalZone    0.073093\n",
      "1                   Longitude    0.071440\n",
      "2                    Latitude    0.070229\n",
      "3            TotalTaxAssessed    0.068707\n",
      "4            TaxAgrarianValue    0.067848\n",
      "5        FieldEstablishedYear    0.066602\n",
      "6                TaxLandValue    0.066412\n",
      "7                  TotalValue    0.066357\n",
      "8     TotalCultivatedAreaSqft    0.060654\n",
      "9         CultivatedAreaSqft1    0.059108\n",
      "10              ValuationYear    0.055788\n",
      "11              RawLocationId    0.054944\n",
      "12         CropSpeciesVariety    0.049404\n",
      "13  MainIrrigationSystemCount    0.032930\n",
      "14      WaterAccessPointsCalc    0.032868\n",
      "15          WaterAccessPoints    0.031775\n",
      "16      AgricultureZoningCode    0.030641\n",
      "17              LandUsageType    0.024751\n",
      "18    StorageAndFacilityCount    0.013959\n",
      "19         NationalRegionCode    0.002489\n"
     ]
    }
   ],
   "source": [
    "# get feature importance using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = train_data\n",
    "y = train_labels\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "feature_importances_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Reset index for readability\n",
    "feature_importances_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with importance less than 0.01\n",
    "columns_to_drop = feature_importances_df[feature_importances_df['Importance'] < 0.05]['Feature'].tolist()\n",
    "\n",
    "# Drop the identified columns from the DataFrame\n",
    "train_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Drop the identified columns from test data\n",
    "test_data.drop(columns=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "2    67541\n",
      "1    67541\n",
      "0    67541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print count of unique values in y\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202623 entries, 0 to 202622\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   AgriculturalPostalZone   202623 non-null  int64  \n",
      " 1   CultivatedAreaSqft1      202623 non-null  float64\n",
      " 2   FieldEstablishedYear     202623 non-null  float64\n",
      " 3   Latitude                 202623 non-null  float64\n",
      " 4   Longitude                202623 non-null  float64\n",
      " 5   RawLocationId            202623 non-null  float64\n",
      " 6   TaxAgrarianValue         202623 non-null  float64\n",
      " 7   TaxLandValue             202623 non-null  float64\n",
      " 8   TotalCultivatedAreaSqft  202623 non-null  float64\n",
      " 9   TotalTaxAssessed         202623 non-null  float64\n",
      " 10  TotalValue               202623 non-null  float64\n",
      " 11  ValuationYear            202623 non-null  float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 18.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add uid to train and test data and save cleaned data\n",
    "# train_data['UID'] = train_data.index\n",
    "# test_data['UID'] = test_data.index\n",
    "\n",
    "# train_data['Target'] = train_labels\n",
    "\n",
    "# train_data.to_csv(\"cleaned_train.csv\", index=False)\n",
    "# test_data.to_csv(\"cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features before training\n",
    "scaler = StandardScaler()\n",
    "train_data = pd.DataFrame(scaler.fit_transform(train_data), columns=train_data.columns, index=train_data.index)\n",
    "test_data = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "# train_data_norm = scaler.fit_transform(train_data)\n",
    "# test_data_norm = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train data with 22514 data of each class\n",
    "\n",
    "# Separate the data based on the target classes\n",
    "low_class = train_data[train_labels == 0]\n",
    "medium_class = train_data[train_labels == 1]\n",
    "high_class = train_data[train_labels == 2]\n",
    "\n",
    "# Get the number of samples in each class\n",
    "low_class_count = len(low_class)\n",
    "medium_class_count = len(medium_class)\n",
    "high_class_count = len(high_class)\n",
    "\n",
    "# Set the number of samples to be selected from each class\n",
    "num_samples = min(low_class_count, medium_class_count, high_class_count)\n",
    "\n",
    "# Randomly sample data from each class\n",
    "low_class_sample = low_class.sample(n=num_samples, random_state=seed)\n",
    "medium_class_sample = medium_class.sample(n=num_samples, random_state=seed)\n",
    "high_class_sample = high_class.sample(n=num_samples, random_state=seed)\n",
    "\n",
    "# Concatenate the sampled data\n",
    "train_data_sampled = pd.concat([low_class_sample, medium_class_sample, high_class_sample])\n",
    "\n",
    "# Separate the features and target variable\n",
    "X_sampled = train_data_sampled\n",
    "y_sampled = train_labels.loc[train_data_sampled.index]\n",
    "\n",
    "# Display the count of unique values in the target variable\n",
    "print(y_sampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (192491, 12)\n",
      "X_valid shape: (10132, 12)\n",
      "y_train shape: (192491,)\n",
      "y_valid shape: (10132,)\n"
     ]
    }
   ],
   "source": [
    "# do data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_labels, test_size=0.05, random_state=seed)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Display the shapes of the training and validation sets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Training F1 Score: 1.0000\n",
      "Validation Accuracy: 0.7138\n",
      "Validation F1 Score: 0.7137\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy and F1 score on the training set\n",
    "train_preds = rf_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "# Accuracy and F1 score on the validation set\n",
    "valid_preds = rf_model.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# Display the accuracy and F1 score\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = rf_model.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest on full data\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model_full = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "rf_model_full.fit(train_data, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_preds = rf_model_full.predict(test_data)\n",
    "\n",
    "# convert predictions to target values\n",
    "target_mapping_inv = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping_inv)\n",
    "\n",
    "# Create a DataFrame with the 'UID' column and the predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes Classifier\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Fit the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy and F1 score on the training set\n",
    "train_preds = nb_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "# Accuracy and F1 score on the validation set\n",
    "valid_preds = nb_model.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# Display the accuracy and F1 score\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions on test data\n",
    "test_preds = nb_model.predict(test_data)\n",
    "\n",
    "# convert predictions to target values\n",
    "target_mapping_inv = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping_inv)\n",
    "\n",
    "# Create a DataFrame with the 'UID' column and the predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "# gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=seed)\n",
    "# ada_clf = AdaBoostClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# # create a voting classifier with soft voting\n",
    "# ensemble_model = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('rf', rf_clf),\n",
    "#         ('gb', gb_clf),\n",
    "#         ('ada', ada_clf)\n",
    "#     ],\n",
    "#     voting='soft'\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# valid_preds = ensemble_model.predict(X_valid)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# # Calculate the F1 score of the model\n",
    "# f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "# print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# # Display the accuracy of the model\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize classifiers with a random seed\n",
    "seed = 42\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=seed)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=seed)\n",
    "log_reg_clf = LogisticRegression(max_iter=1000, random_state=seed)\n",
    "svc_clf = SVC(kernel='rbf', probability=True, random_state=seed)  # SVM with soft voting\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Create a voting classifier with soft voting\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_clf),\n",
    "        ('gb', gb_clf),\n",
    "        ('ada', ada_clf),\n",
    "        ('log_reg', log_reg_clf),\n",
    "        ('svc', svc_clf),\n",
    "        ('nb', nb_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_preds = ensemble_model.predict(X_train)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "valid_preds = ensemble_model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "\n",
    "# Display the F1 scores\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = ensemble_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print count of unique values in predictions\n",
    "print(np.unique(test_preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.6326\n",
      "Validation F1 Score: 0.5792\n",
      "Training Accuracy: 0.6416\n",
      "Validation Accuracy: 0.5914\n"
     ]
    }
   ],
   "source": [
    "# Use XGBoost\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_preds = xgb_model.predict(X_train)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "valid_preds = xgb_model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# Display the F1 scores\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.5159\n",
      "Validation F1 Score: 0.5166\n",
      "Training Accuracy: 0.5322\n",
      "Validation Accuracy: 0.5332\n"
     ]
    }
   ],
   "source": [
    "# ver_1 xgboost\n",
    "xgb_v1 = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    n_estimators=200,\n",
    "    max_depth=2,\n",
    "    random_state=seed\n",
    ") \n",
    "\n",
    "# Fit the model\n",
    "xgb_v1.fit(X_train, y_train)\n",
    "\n",
    "# get accuracy and f1 score on training set and validation set\n",
    "train_preds = xgb_v1.predict(X_train)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "\n",
    "valid_preds = xgb_v1.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# Display the F1 scores\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=seed),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'max_depth': [ 2, 3, 4, 5, 6, 7],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5, \n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(**fixed_params),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 9 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/darpan/Documents/.venv/test/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.65660469 0.66495585 0.16673354        nan 0.6655152  0.65650437\n",
      " 0.66619965 0.16673354        nan 0.6658143  0.65732709 0.6658633\n",
      " 0.16673354        nan 0.66563984 0.65782722 0.66480892 0.16673354\n",
      "        nan 0.6655152  0.65782722 0.66480892 0.16673354        nan\n",
      " 0.6655152 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_delta_step': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "cv_params = {\n",
    "    'subsample': [0.6, 0.8, 0,9, 1.0],\n",
    "    'max_delta_step': [0, 1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "csv = GridSearchCV(\n",
    "    estimator=XGBClassifier(**fixed_params),\n",
    "    param_grid=cv_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "csv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = csv.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.8273\n",
      "Validation F1 Score: 0.6585\n",
      "Training Accuracy: 0.8278\n",
      "Validation Accuracy: 0.6619\n"
     ]
    }
   ],
   "source": [
    "final_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.8,\n",
    "    'max_delta_step': 1,\n",
    "    'random_state': seed\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(**final_params)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_preds = xgb_model.predict(X_train)\n",
    "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "valid_preds = xgb_model.predict(X_valid)\n",
    "valid_f1 = f1_score(y_valid, valid_preds, average='macro')\n",
    "valid_accuracy = accuracy_score(y_valid, valid_preds)\n",
    "\n",
    "# Display the F1 scores\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {valid_f1:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictinos on test data\n",
    "test_preds = xgb_model.predict(test_data)\n",
    "\n",
    "# convert predictions to original target values\n",
    "target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "test_preds = pd.Series(test_preds).map(target_mapping)\n",
    "\n",
    "# make csv file for submission\n",
    "submission = pd.DataFrame({\n",
    "    'UID': test_data.index,\n",
    "    'Target': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning for XGBoost to get max F1 macro score on validation set \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_fname, predictions_fname):\n",
    "    # Load the test data\n",
    "    test_data = pd.read_csv(test_fname)\n",
    "\n",
    "    predictions = np.array([random.choice([0, 1, 2]) for _ in range(len(test_data))])\n",
    "\n",
    "    # map 0 -> low, 1 -> medium, 2 -> high\n",
    "    predictions = np.array(['low', 'medium', 'high'])[predictions]\n",
    "\n",
    "    # Save the predictions to CSV file containing UID and Target columns\n",
    "    pd.DataFrame({\n",
    "        'UID': test_data['UID'],\n",
    "        'Target': predictions\n",
    "    }).to_csv(predictions_fname, index=False)\n",
    "\n",
    "\n",
    "# make_predictions(\"test.csv\", \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
